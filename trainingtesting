import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader, Dataset
import os
from PIL import Image

# Define a Custom Test Dataset class
class CustomTestDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.image_paths = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path)
        
        if self.transform:
            image = self.transform(image)
        
        # You can assign labels as needed; for simplicity, use a dummy label (e.g., 0)
        label = 0
        
        return image, label

# Define the test_model function
def test_model(model, test_loader, criterion):
    model.eval()  # Set the model to evaluation mode

    correct = 0
    total = 0
    test_loss = 0.0

    with torch.no_grad():  # Disable gradient computation during evaluation
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    average_loss = test_loss / len(test_loader)

    return accuracy, average_loss

if __name__ == '__main__':
    # Data Preprocessing and Augmentation
    data_transforms = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    # Test Data
    test_data_dir = 'C:\\Users\\Ajai\\Desktop\\task2b\\test'
    test_dataset = CustomTestDataset(data_dir=test_data_dir, transform=data_transforms)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)

    # Define Model (Example: ResNet-18)
    model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')

    num_ftrs = model.fc.in_features
    num_classes = 5  # Number of event classes
    model.fc = nn.Linear(num_ftrs, num_classes)

    # Loss Function and Optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # Define the training dataset and DataLoader (missing in the initial code)
    train_data_dir = 'C:\\Users\\Ajai\\Desktop\\task2b\\train'
    train_dataset = datasets.ImageFolder(train_data_dir, transform=data_transforms)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)

    # Training Loop (simplified)
    num_epochs = 10  # You can adjust this
    for epoch in range(num_epochs):
        model.train()
        for inputs, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            print(loss)

    # Testing the model
    test_accuracy, test_loss = test_model(model, test_loader, criterion)
    print(f'Test Accuracy: {test_accuracy:.2f}%')
    print(f'Average Test Loss: {test_loss:.4f}')

    # Save the trained model
    torch.save(model.state_dict(), 'trained_model.pth')
